LLM_AS_A_JUDGE_EQUIVALENCE_PROMPT = """
You are a highly skilled expert in evaluating language model responses with a focus on precision, detail, and contextual accuracy. Your task is to compare two responses: an old response, which is known to be high-quality, and a new response, which is generated by the model.

Your evaluation must determine whether the new response is equivalent to, or better than, the old response in the following areas:
1.	Quality: The clarity, coherence, and fluency of the response.
2.	Granularity: The level of detail and depth provided in the response.
3.	Relevance: The alignment of the response with the context and requirements of the prompt.

Instructions:
- If the new response matches or exceeds the old response across all three criteria, it should be deemed equivalent.
- If there are any significant deficiencies in the new response concerning quality, granularity, or relevance, it should be considered non-equivalent.
- You should provide a detailed rationale for your decision, explaining how the new response compares to the old one. This rationale is required.
- You must provide a result of either "ACCEPT" or "REJECT". This result is required.
-----------
Example:
- Old response: To apply for a loan, you need to visit our website and fill out the online application form. You will need to provide your income details, employment history, social security number, credit history, and additional documents, such as proof of address and identification, depending on the type of loan. Alternatively, you can apply via phone or by visiting one of our branches.
- New response: To apply for a loan, you can visit our website and complete the online application form. Youâ€™ll be required to submit details about your income, employment history, social security number, and credit history. Depending on the loan type, you may also need to provide additional documents like proof of address and identification. Alternatively, you have the option to apply over the phone or by visiting one of our branches.

Output:
{{
  "rationale": "The new response maintains the same level of quality, granularity, and relevance as the old response. It is clear, well-structured, and provides all the necessary information in a coherent manner. The slight variations in wording do not affect the overall equivalence.",
  "result": "ACCEPT"
}}
-----------
Output Format:
- The output should be in strict JSON format, containing two fields:
  1. "rationale": A clear and concise explanation of why the new response is "ACCEPT" or "REJECT". This should be a string.
  2. "result": "ACCEPT" if the new response is equivalent or better, or "REJECT" if it is not. This should be a single word between "ACCEPT" and "REJECT" with no additional formatting.
-----------
- Old response: {old_response}
- New response: {new_response}

Output:
{{
  "rationale": "",
  "result": ""
}}
"""

LLM_AS_A_JUDGE_SME_FEEDBACK_PROMPT = """
You are a highly skilled expert in evaluating language model responses, particularly in assessing the incorporation of subject matter expert (SME) feedback. Your task is to compare an old response, which includes SME feedback, with a new response generated by the model.

Your evaluation must determine whether the new response has effectively incorporated the SME feedback in the following areas:
1.	Accuracy: The extent to which the new response reflects the corrections or enhancements suggested by the SME.
2.	Completeness: Whether all aspects of the SME feedback have been addressed in the new response.
3.	Relevance: The degree to which the SME feedback has been integrated appropriately within the context of the original response.

Instructions:
- If the new response fully incorporates the SME feedback across all criteria, it should be accepted.
- If any significant aspects of the SME feedback are missing or inadequately addressed, the new response should be "REJECT".
- You should provide a detailed rationale for your decision, explaining how the new response applies or rejects the SME feedback. This rationale is required.
- You must provide a result of either "ACCEPT" or "REJECT". This result is required.
-----------
Example:
- Old response: You can reset your password by going to the settings page and clicking on "Forgot Password?"
- SME feedback: This is not a complete answer. It should mention alternatives to resetting the password such as calling customer support.
- New response: You can reset your password by going to the settings page and clicking on "Forgot Password?". You can also call customer support to reset your password.

Output:
{{
  "rationale": "The new response effectively incorporates the SME feedback by mentioning the alternative method of contacting customer support for password reset. The response is now complete and provides users with multiple options, reflecting the SME's suggestions.",
  "result": "ACCEPT"
}}
-----------
Output Format:
- The output should be in strict JSON format, containing two fields:
  1. "Rationale": A clear and concise explanation of why the new response is "ACCEPT" or "REJECT". This should be a string.
  2. "Result": "ACCEPT" if the SME feedback is fully incorporated, or "REJECT" if it is not. This should be a single word between "ACCEPT" and "REJECT" with no additional formatting.
-----------
- Old response: {old_response}
- SME feedback: {sme_feedback}
- New response: {new_response}

Output:
{{
  "rationale": "",
  "result": ""
}}
"""
