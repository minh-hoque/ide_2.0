# LLM_AS_A_JUDGE_EQUIVALENCE_PROMPT = """
# You are an expert at evaluating responses.
# You will be given an old response and a new response. Evaluate if the new response is equivalent to the old response and provide a clear rational.
# The new response is equivalent to the old response if the new response is at the same or better level of quality, granularity, and relevance as the old response.
# If the new response is equivalent to the old response, return "ACCEPT". Otherwise, return "REJECT". Provide a clear rational on why it is "ACCEPT" or "REJECT".

# The output format should be:
# rational: A clear rational on why it is "ACCEPT" or "REJECT"
# result: ACCEPT or REJECT
# -----------
# Example:
# old response: To apply for a loan, you need to visit our website and fill out the online application form. You will need to provide your income details, employment history, social security number, credit history and additional documents, such as proof of address and identification, depending on the type of loan. Alternatively, you can apply via phone or by visiting one of our branches.
# new response: To apply for a loan, you can visit our website and complete the online application form. You’ll be required to submit details about your income, employment history, social security number, and credit history. Depending on the loan type, you may also need to provide additional documents like proof of address and identification. Alternatively, you have the option to apply over the phone or by visiting one of our branches.

# Output:
# rational: This response is at the same or better level of quality, granularity, and relevance as the old response.
# result: ACCEPT
# -----------
# old response: {old_response}
# new response: {new_response}
# rational:
# result:
# """


LLM_AS_A_JUDGE_EQUIVALENCE_PROMPT = """
You are a highly skilled expert in evaluating language model responses with a focus on precision, detail, and contextual accuracy. Your task is to compare two responses: an old response, which is known to be high-quality, and a new response, which is generated by the model.

Your evaluation must determine whether the new response is equivalent to, or better than, the old response in terms of the following criteria:
1.	Quality: The clarity, coherence, and fluency of the response.
2.	Granularity: The level of detail and depth provided in the response.
3.	Relevance: The alignment of the response with the context and requirements of the prompt.

Instructions:
- If the new response matches or exceeds the old response across all three criteria, it should be deemed equivalent.
- If there are any significant deficiencies in the new response concerning quality, granularity, or relevance, it should be considered non-equivalent.
- You should provide a detailed rationale for your decision, explaining how the new response compares to the old one. This rationale is required.
- You must provide a result of either “ACCEPT” or “REJECT.” This result is required.

Output Format:
- Rationale: A clear and detailed explanation of why the new response is “ACCEPT” or “REJECT,” focusing on the three criteria.
- Result: “ACCEPT” if the new response is equivalent or better, or “REJECT” if it is not.
-----------
Example:
Old response: To apply for a loan, you need to visit our website and fill out the online application form. You will need to provide your income details, employment history, social security number, credit history, and additional documents, such as proof of address and identification, depending on the type of loan. Alternatively, you can apply via phone or by visiting one of our branches.
New response: To apply for a loan, you can visit our website and complete the online application form. You’ll be required to submit details about your income, employment history, social security number, and credit history. Depending on the loan type, you may also need to provide additional documents like proof of address and identification. Alternatively, you have the option to apply over the phone or by visiting one of our branches.
Rationale: The new response maintains the same level of quality, granularity, and relevance as the old response. It is clear, well-structured, and provides all the necessary information in a coherent manner. The slight variations in wording do not affect the overall equivalence.
Result: ACCEPT
-----------
Old response: {old_response}
New response: {new_response}
Rationale:
Result:
"""

# LLM_AS_A_JUDGE_SME_FEEDBACK_PROMPT = """
# You are an expert at evaluating responses.
# You will be given an old response with SME feedback and a new response. Evaluate if the new response has incorporated the SME feedback into the new response and provide a clear rational.
# If the new response has incorporated the SME feedback into the new response, return "ACCEPT". Otherwise, return "REJECT". Provide a clear rational on why it is "ACCEPT" or "REJECT"

# Output Format:
# - Rationale: A clear and detailed explanation of why the new response is “ACCEPT” or “REJECT,” focusing on the three criteria.
# - Result: “ACCEPT” if the new response is equivalent or better, or “REJECT” if it is not.
# -----------
# Example:
# Old response: You can reset your password by going to the settings page and clicking on "Forgot Password?"
# SME feedback: This is not a complete answer. It should mention alternatives to resetting the password such as calling customer support.
# New response: You can reset your password by going to the settings page and clicking on "Forgot Password?". You can also call customer support to reset your password.

# Output:
# Rationale: This response has incorporated the SME feedback into the new response such as mentioning alternatives to resetting the password.
# Result: ACCEPT
# -----------
# Old response: {old_response}
# SME feedback: {sme_feedback}
# New response: {new_response}
# Rationale:
# Result:
# """


LLM_AS_A_JUDGE_SME_FEEDBACK_PROMPT = """
You are a highly skilled expert in evaluating language model responses, particularly in assessing the incorporation of subject matter expert (SME) feedback. Your task is to compare an old response, which includes SME feedback, with a new response generated by the model.

Your evaluation must determine whether the new response has effectively incorporated the SME feedback in the following areas:
1.	Accuracy: The extent to which the new response reflects the corrections or enhancements suggested by the SME.
2.	Completeness: Whether all aspects of the SME feedback have been addressed in the new response.
3.	Relevance: The degree to which the SME feedback has been integrated appropriately within the context of the original response.

Instructions:
- If the new response fully incorporates the SME feedback across all criteria, it should be accepted.
- If any significant aspects of the SME feedback are missing or inadequately addressed, the new response should be rejected.
- You should provide a detailed rationale for your decision, explaining how the new response applies or rejects the SME feedback. This rationale is required.
- You must provide a result of either “ACCEPT” or “REJECT.” This result is required.

Output Format:
- Rationale: A clear and detailed explanation of why the new response is “ACCEPT” or “REJECT,” with reference to accuracy, completeness, and relevance.
- Result: “ACCEPT” if the SME feedback is fully incorporated, or “REJECT” if it is not.
-----------
Example:
Old response: You can reset your password by going to the settings page and clicking on "Forgot Password?"
SME feedback: This is not a complete answer. It should mention alternatives to resetting the password such as calling customer support.
New response: You can reset your password by going to the settings page and clicking on "Forgot Password?". You can also call customer support to reset your password.
Rationale: The new response effectively incorporates the SME feedback by mentioning the alternative method of contacting customer support for password reset. The response is now complete and provides users with multiple options, reflecting the SME’s suggestions.
Result: ACCEPT
-----------
Old response: {old_response}
SME feedback: {sme_feedback}
New response: {new_response}
Rationale:
Result:
"""
